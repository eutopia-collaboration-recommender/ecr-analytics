{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f31bd1add2ced50",
   "metadata": {},
   "source": [
    "# New collaborations impact author's research direction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa87deb662af8dfb",
   "metadata": {},
   "source": [
    "### Brief overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14716f88a14b222",
   "metadata": {},
   "source": [
    "### Imports & Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "72f50eee558e17ca",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T16:02:25.641131Z",
     "start_time": "2024-12-26T16:02:25.630130Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost\n",
    "\n",
    "from box import Box\n",
    "from sklearn.metrics import accuracy_score, recall_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from util.postgres import create_sqlalchemy_connection, query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c63a4e38ce2836a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T15:58:44.446940Z",
     "start_time": "2024-12-26T15:58:44.226497Z"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------- GLOBAL VARIABLES --------------------\n",
    "PATH_TO_CONFIG_FILE = '../config.yaml'\n",
    "\n",
    "# -------------------- LOAD CONFIGURATION --------------------\n",
    "# Load the configuration file\n",
    "config = Box.from_yaml(filename=PATH_TO_CONFIG_FILE)\n",
    "# Initialize a BigQuery client\n",
    "pg_connection = create_sqlalchemy_connection(\n",
    "    username=config.POSTGRES.USERNAME,\n",
    "    password=config.POSTGRES.PASSWORD,\n",
    "    host=config.POSTGRES.HOST,\n",
    "    port=config.POSTGRES.PORT,\n",
    "    database=config.POSTGRES.DATABASE,\n",
    "    schema=config.POSTGRES.SCHEMA\n",
    ")\n",
    "# Set numpy random seed\n",
    "np.random.seed(config.RANDOM_SEED)\n",
    "\n",
    "n_authors = 1000\n",
    "n_min_articles = 15\n",
    "n_top_articles = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "669d0a97026eda24",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T15:58:48.892539Z",
     "start_time": "2024-12-26T15:58:44.914020Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_query = f\"\"\"\n",
    "WITH authors AS (SELECT DISTINCT author_id\n",
    "                 FROM fct_collaboration\n",
    "                 GROUP BY author_id\n",
    "                 HAVING COUNT(DISTINCT article_id) > {n_min_articles}\n",
    "                 ORDER BY author_id\n",
    "                 LIMIT {n_authors}),\n",
    "     articles AS (SELECT DISTINCT c.author_id,\n",
    "                                  c.article_id,\n",
    "                                  c.article_publication_dt,\n",
    "                                  CASE\n",
    "                                      WHEN c.has_new_author_collaboration THEN 'new'\n",
    "                                      ELSE 'existing' END AS collaboration_type\n",
    "                  FROM fct_collaboration c\n",
    "                           INNER JOIN authors a\n",
    "                                      ON c.author_id = a.author_id\n",
    "                  WHERE c.is_single_author_collaboration = FALSE\n",
    "                    AND c.article_id IN (SELECT article_id\n",
    "                                         FROM article_text_embedding))\n",
    "SELECT author_id,\n",
    "       article_id,\n",
    "       article_publication_dt,\n",
    "       collaboration_type\n",
    "FROM articles\n",
    "ORDER BY author_id, article_publication_dt\n",
    "\"\"\"\n",
    "\n",
    "df = query(conn=pg_connection, query_str=sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bdb41eb236356587",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T16:00:17.042383Z",
     "start_time": "2024-12-26T15:58:48.911536Z"
    }
   },
   "outputs": [],
   "source": [
    "sql_query = f\"\"\"\n",
    "WITH authors AS (SELECT DISTINCT author_id\n",
    "                 FROM fct_collaboration\n",
    "                 GROUP BY author_id\n",
    "                 HAVING COUNT(DISTINCT article_id) > {n_min_articles}\n",
    "                 ORDER BY author_id\n",
    "                 LIMIT {n_authors}),\n",
    "     articles AS (SELECT DISTINCT c.article_id\n",
    "                  FROM fct_collaboration c\n",
    "                           INNER JOIN authors a\n",
    "                                      ON c.author_id = a.author_id\n",
    "                  WHERE c.is_single_author_collaboration = FALSE\n",
    "                    AND c.article_id IN (SELECT article_id\n",
    "                                         FROM article_text_embedding))\n",
    "SELECT t.article_id,\n",
    "       t.article_text_embedding\n",
    "FROM article_text_embedding t\n",
    "INNER JOIN articles a USING (article_id)\n",
    "ORDER BY t.article_id\n",
    "\"\"\"\n",
    "\n",
    "df_embedding = query(conn=pg_connection, query_str=sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f914ec6e69bf38f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T17:34:27.605410Z",
     "start_time": "2024-12-26T17:33:21.109286Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 998/998 [01:34<00:00, 10.53it/s]\n"
     ]
    }
   ],
   "source": [
    "results = dict(\n",
    "    similarities=[],\n",
    "    closest_articles=[]\n",
    ")\n",
    "\n",
    "for author_id in tqdm(df['author_id'].unique()):\n",
    "    # Get the author's articles and sort them by publication date\n",
    "    df_author_articles = (df[df['author_id'] == author_id]\n",
    "                          .sort_values(\"article_publication_dt\")\n",
    "                          .reset_index(drop=True))\n",
    "\n",
    "    # Article embeddings of the author's articles indexed same as df_author_articles\n",
    "    df_author_article_embeddings = (\n",
    "        df_embedding[df_embedding['article_id'].isin(df_author_articles['article_id'])]\n",
    "        .set_index(\"article_id\")\n",
    "        .reindex(df_author_articles[\"article_id\"])\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    # Vertical stack of article embeddings\n",
    "    author_article_embeddings = np.vstack(df_author_article_embeddings[\"article_text_embedding\"].values)\n",
    "\n",
    "    # Using cosine distance to calculate the distance matrix for all author's articles\n",
    "    S = cosine_similarity(author_article_embeddings)\n",
    "\n",
    "    # Iterate over the author's articles\n",
    "    for idx, row in df_author_articles.iterrows():\n",
    "        # Get the current article's information\n",
    "        article_id = row['article_id']\n",
    "        collaboration_type = row['collaboration_type']\n",
    "        article_publication_dt = row['article_publication_dt']\n",
    "\n",
    "        # Find current article's index in the author's article dataframe\n",
    "        current_index = df_author_articles.index[df_author_articles[\"article_id\"] == article_id][0]\n",
    "        # Create before/after masks\n",
    "        before_mask = df_author_articles[\"article_publication_dt\"] < article_publication_dt\n",
    "        after_mask = df_author_articles[\"article_publication_dt\"] > article_publication_dt\n",
    "        # Fetch indices of the articles before and after the current article\n",
    "        before_indices = np.where(before_mask)[0]\n",
    "        after_indices = np.where(after_mask)[0]\n",
    "\n",
    "        # If there are not enough articles before or after the current article, skip\n",
    "        if len(before_indices) < n_top_articles or len(after_indices) < n_top_articles:\n",
    "            continue\n",
    "\n",
    "        # Calculate top n most similar articles before the current article\n",
    "        similarities_before = S[current_index, before_indices]\n",
    "        idx_top_n_before_in_similarities_before = np.argsort(similarities_before)[::-1][:n_top_articles]\n",
    "\n",
    "        # Calculate top n most similar articles after the current article\n",
    "        similarities_after = S[current_index, after_indices]\n",
    "        idx_top_n_after_in_similarities_after = np.argsort(similarities_after)[::-1][:n_top_articles]\n",
    "\n",
    "        # Get the embeddings of the top n most similar articles before and after\n",
    "        embeddings_before = author_article_embeddings[idx_top_n_before_in_similarities_before]\n",
    "        embeddings_after = author_article_embeddings[idx_top_n_after_in_similarities_after]\n",
    "\n",
    "        # Calculate the cosine similarity between the current article and the top n most similar articles before and after\n",
    "        S_top = cosine_similarity(embeddings_before, embeddings_after)\n",
    "\n",
    "        # Cross-compare the top n most similar articles before and after the current article\n",
    "        for idy in range(n_top_articles):\n",
    "            results['similarities'].extend(\n",
    "                [\n",
    "                    dict(\n",
    "                        article_id=article_id,\n",
    "                        article_publication_dt=article_publication_dt,\n",
    "                        similarity=S_top[idy][idz],\n",
    "                        collaboration_type=collaboration_type\n",
    "                    ) for idz in range(n_top_articles)\n",
    "                ]\n",
    "            )\n",
    "\n",
    "            results['closest_articles'].append(\n",
    "                dict(\n",
    "                    article_id=article_id,\n",
    "                    similar_article_id=df_author_articles.loc[\n",
    "                        idx_top_n_before_in_similarities_before[idy], \"article_id\"],\n",
    "                    article_embedding=author_article_embeddings[current_index],\n",
    "                    similar_article_embedding=author_article_embeddings[idx_top_n_before_in_similarities_before[idy]],\n",
    "                    collaboration_type=collaboration_type,\n",
    "                    timeline='before'\n",
    "                )\n",
    "            )\n",
    "\n",
    "            results['closest_articles'].append(\n",
    "                dict(\n",
    "                    article_id=article_id,\n",
    "                    similar_article_id=df_author_articles.loc[\n",
    "                        idx_top_n_after_in_similarities_after[idy], \"article_id\"],\n",
    "                    article_embedding=author_article_embeddings[current_index],\n",
    "                    similar_article_embedding=author_article_embeddings[idx_top_n_after_in_similarities_after[idy]],\n",
    "                    collaboration_type=collaboration_type,\n",
    "                    timeline='after'\n",
    "                )\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7c8a1ab1cd1c14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T16:36:59.449289Z",
     "start_time": "2024-12-26T16:36:52.022227Z"
    }
   },
   "outputs": [],
   "source": [
    "df_similarities = pd.DataFrame(results['similarities'])\n",
    "\n",
    "sns.histplot(data=df_similarities, x='similarity', hue='collaboration_type', kde=True)\n",
    "# Add medians\n",
    "medians = df_similarities.groupby('collaboration_type')['similarity'].median()\n",
    "for i, median in medians.items():\n",
    "    print(f'{i} median: {median:.2f}')\n",
    "    plt.axvline(median, color='g', linestyle='--', label=f'{i} median')\n",
    "plt.title(\"Distribution of cosine similarity between articles\")\n",
    "plt.xlabel('Similarity')\n",
    "plt.ylim(0, 6000)\n",
    "plt.xlim(0.7, 0.95)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "100300c5e66491c7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T17:40:16.815771Z",
     "start_time": "2024-12-26T17:40:16.551728Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>similar_article_id</th>\n",
       "      <th>article_embedding</th>\n",
       "      <th>similar_article_embedding</th>\n",
       "      <th>collaboration_type</th>\n",
       "      <th>timeline</th>\n",
       "      <th>timeline_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2-s2.0-84864483652</td>\n",
       "      <td>2-s2.0-84860423756</td>\n",
       "      <td>[0.02254791185259819, 0.059315506368875504, -0...</td>\n",
       "      <td>[0.03704354912042618, 0.06055133417248726, -0....</td>\n",
       "      <td>existing</td>\n",
       "      <td>before</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2-s2.0-84864483652</td>\n",
       "      <td>2-s2.0-79551660274</td>\n",
       "      <td>[0.02254791185259819, 0.059315506368875504, -0...</td>\n",
       "      <td>[0.047482769936323166, 0.0404452346265316, -0....</td>\n",
       "      <td>existing</td>\n",
       "      <td>after</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2-s2.0-84864483652</td>\n",
       "      <td>2-s2.0-70350514742</td>\n",
       "      <td>[0.02254791185259819, 0.059315506368875504, -0...</td>\n",
       "      <td>[0.028228508308529854, 0.0690259039402008, -0....</td>\n",
       "      <td>existing</td>\n",
       "      <td>before</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-s2.0-84864483652</td>\n",
       "      <td>2-s2.0-84898992795</td>\n",
       "      <td>[0.02254791185259819, 0.059315506368875504, -0...</td>\n",
       "      <td>[0.06195266544818878, 0.05602636560797691, -0....</td>\n",
       "      <td>existing</td>\n",
       "      <td>after</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2-s2.0-84864483652</td>\n",
       "      <td>2-s2.0-58149092669</td>\n",
       "      <td>[0.02254791185259819, 0.059315506368875504, -0...</td>\n",
       "      <td>[0.03938606008887291, 0.0580519400537014, -0.0...</td>\n",
       "      <td>existing</td>\n",
       "      <td>before</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           article_id  similar_article_id  \\\n",
       "0  2-s2.0-84864483652  2-s2.0-84860423756   \n",
       "1  2-s2.0-84864483652  2-s2.0-79551660274   \n",
       "2  2-s2.0-84864483652  2-s2.0-70350514742   \n",
       "3  2-s2.0-84864483652  2-s2.0-84898992795   \n",
       "4  2-s2.0-84864483652  2-s2.0-58149092669   \n",
       "\n",
       "                                   article_embedding  \\\n",
       "0  [0.02254791185259819, 0.059315506368875504, -0...   \n",
       "1  [0.02254791185259819, 0.059315506368875504, -0...   \n",
       "2  [0.02254791185259819, 0.059315506368875504, -0...   \n",
       "3  [0.02254791185259819, 0.059315506368875504, -0...   \n",
       "4  [0.02254791185259819, 0.059315506368875504, -0...   \n",
       "\n",
       "                           similar_article_embedding collaboration_type  \\\n",
       "0  [0.03704354912042618, 0.06055133417248726, -0....           existing   \n",
       "1  [0.047482769936323166, 0.0404452346265316, -0....           existing   \n",
       "2  [0.028228508308529854, 0.0690259039402008, -0....           existing   \n",
       "3  [0.06195266544818878, 0.05602636560797691, -0....           existing   \n",
       "4  [0.03938606008887291, 0.0580519400537014, -0.0...           existing   \n",
       "\n",
       "  timeline  timeline_label  \n",
       "0   before               0  \n",
       "1    after               1  \n",
       "2   before               0  \n",
       "3    after               1  \n",
       "4   before               0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_closest_articles = pd.DataFrame(results['closest_articles'])\n",
    "df_closest_articles['timeline_label'] = df_closest_articles['timeline'].map({'before': 0, 'after': 1})\n",
    "df_closest_articles.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a15c39233566fc72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T17:52:32.170154Z",
     "start_time": "2024-12-26T17:52:32.074506Z"
    }
   },
   "outputs": [],
   "source": [
    "n_before = df_closest_articles[df_closest_articles['timeline'] == 'before']\n",
    "n_after = df_closest_articles[df_closest_articles['timeline'] == 'after']\n",
    "n_samples = min(len(n_before), len(n_after))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "893c0b2237746a54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T17:56:50.216474Z",
     "start_time": "2024-12-26T17:53:47.990998Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 259890/259890 [01:56<00:00, 2223.84it/s]\n"
     ]
    }
   ],
   "source": [
    "X = list()\n",
    "y = list()\n",
    "ix_before = 0\n",
    "ix_after = 0\n",
    "for i in tqdm(range(len(df_closest_articles))):\n",
    "    if df_closest_articles.loc[i, 'timeline'] == 'before' and ix_before >= n_samples:\n",
    "        continue\n",
    "    if df_closest_articles.loc[i, 'timeline'] == 'after' and ix_after >= n_samples:\n",
    "        continue\n",
    "\n",
    "    sim_emb = df_closest_articles.loc[i, 'similar_article_embedding']\n",
    "    art_emb = df_closest_articles.loc[i, 'article_embedding']\n",
    "    # Convert to list (in case they're NumPy arrays), then concatenate\n",
    "    combined_emb = list(sim_emb) + list(art_emb)\n",
    "    X.append(combined_emb)\n",
    "    y.append(df_closest_articles.loc[i, 'timeline_label'])\n",
    "\n",
    "X = np.array(X)  # shape will be (num_samples, dim_sim + dim_art)\n",
    "\n",
    "# ------------------------\n",
    "# 2. Train/Test Split (80/20)\n",
    "# ------------------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7f47eccf1e591820",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-26T18:01:08.369788Z",
     "start_time": "2024-12-26T17:57:18.942149Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6725\n",
      "Recall:   0.6272\n"
     ]
    }
   ],
   "source": [
    "model = xgboost.XGBClassifier(\n",
    "    random_state=42,\n",
    "    eval_metric='logloss'\n",
    ")\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Recall:   {recall:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
