{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f31bd1add2ced50",
   "metadata": {},
   "source": [
    "# New collaborations are driven by search for expertise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa87deb662af8dfb",
   "metadata": {},
   "source": [
    "### Brief overview\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14716f88a14b222",
   "metadata": {},
   "source": [
    "### Imports & Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72f50eee558e17ca",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2024-12-27T13:09:03.615334Z"
    },
    "jupyter": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath(\"..\"))\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "import math\n",
    "from scipy.spatial.distance import cosine\n",
    "from scipy.stats import wasserstein_distance\n",
    "from collections import defaultdict\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "from box import Box\n",
    "from util.postgres import create_sqlalchemy_engine, query_polars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c63a4e38ce2836a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T17:53:42.960863Z",
     "start_time": "2024-12-17T17:53:42.876588Z"
    }
   },
   "outputs": [],
   "source": [
    "# -------------------- GLOBAL VARIABLES --------------------\n",
    "PATH_TO_CONFIG_FILE = '../config.yaml'\n",
    "\n",
    "# -------------------- LOAD CONFIGURATION --------------------\n",
    "# Load the configuration file\n",
    "config = Box.from_yaml(filename=PATH_TO_CONFIG_FILE)\n",
    "# Initialize a BigQuery client\n",
    "pg_engine = create_sqlalchemy_engine(\n",
    "    username=config.POSTGRES.USERNAME,\n",
    "    password=config.POSTGRES.PASSWORD,\n",
    "    host=config.POSTGRES.HOST,\n",
    "    port=config.POSTGRES.PORT,\n",
    "    database=config.POSTGRES.DATABASE,\n",
    "    schema=config.POSTGRES.SCHEMA\n",
    ")\n",
    "# Set numpy random seed\n",
    "np.random.seed(config.RANDOM_SEED)\n",
    "batch_size = 10000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590a4f9a-4797-4ac1-a5f8-54d3224a9828",
   "metadata": {},
   "source": [
    "### Querying the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bed298a0-577d-4d76-ae59-38288870fe63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows fetched 10000 for batch 0\n",
      "Rows fetched 10000 for batch 1\n",
      "Rows fetched 10000 for batch 2\n",
      "Rows fetched 10000 for batch 3\n",
      "Rows fetched 10000 for batch 4\n",
      "Rows fetched 10000 for batch 5\n",
      "Rows fetched 10000 for batch 6\n",
      "Rows fetched 10000 for batch 7\n",
      "Rows fetched 10000 for batch 8\n",
      "Rows fetched 10000 for batch 9\n",
      "Rows fetched 10000 for batch 10\n",
      "Rows fetched 10000 for batch 11\n",
      "Rows fetched 10000 for batch 12\n",
      "Rows fetched 10000 for batch 13\n",
      "Rows fetched 10000 for batch 14\n",
      "Rows fetched 10000 for batch 15\n",
      "Rows fetched 10000 for batch 16\n",
      "Rows fetched 10000 for batch 17\n",
      "Rows fetched 10000 for batch 18\n",
      "Rows fetched 10000 for batch 19\n",
      "Rows fetched 10000 for batch 20\n",
      "Rows fetched 10000 for batch 21\n",
      "Rows fetched 10000 for batch 22\n",
      "Rows fetched 10000 for batch 23\n",
      "Rows fetched 10000 for batch 24\n",
      "Rows fetched 10000 for batch 25\n",
      "Rows fetched 10000 for batch 26\n",
      "Rows fetched 10000 for batch 27\n",
      "Rows fetched 10000 for batch 28\n",
      "Rows fetched 10000 for batch 29\n",
      "Rows fetched 10000 for batch 30\n",
      "Rows fetched 10000 for batch 31\n",
      "Rows fetched 10000 for batch 32\n",
      "Rows fetched 10000 for batch 33\n",
      "Rows fetched 10000 for batch 34\n",
      "Rows fetched 10000 for batch 35\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with pg_engine.raw_connection().cursor() as cur:\n",
    "    cur.execute(\"\"\"\n",
    "        SELECT article_id, article_embedding\n",
    "        FROM g_included_article_embedding\n",
    "    \"\"\")\n",
    "    # Initialize the Polars DataFrame\n",
    "    article_embedding_df: pl.DataFrame = pl.DataFrame()\n",
    "    ix = 0\n",
    "    # Fetch in chunks\n",
    "    while True:\n",
    "        rows = cur.fetchmany(size=batch_size)\n",
    "        if not rows:\n",
    "            break\n",
    "        # Append the rows to the Polars DataFrame\n",
    "        df_chunk = pl.DataFrame(rows, schema=[\"article_id\", \"article_embedding\"], orient=\"row\")\n",
    "    \n",
    "        # Concatenate chunk with the master DataFrame\n",
    "        article_embedding_df = pl.concat([article_embedding_df, df_chunk], how=\"vertical\")\n",
    "        print(f\"Rows fetched {batch_size} for batch {ix}\")\n",
    "        ix += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "c0686a2a-916b-4892-a894-4812aaeb632d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 15.1 s, sys: 2.46 s, total: 17.6 s\n",
      "Wall time: 29.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sql_query = f\"\"\"\n",
    "SELECT f.article_id,\n",
    "       f.author_id,\n",
    "       f.co_author_id,\n",
    "       f.is_new_author_pair,\n",
    "       a.article_publication_dt\n",
    "FROM fct_new_author_pair f\n",
    "    INNER JOIN dim_article a \n",
    "        ON a.article_id = f.article_id\n",
    "WHERE f.author_id IN (SELECT author_id FROM g_included_author)\n",
    "    AND f.co_author_id IN (SELECT author_id FROM g_included_author)\n",
    "\"\"\"\n",
    "with pg_engine.connect() as conn:\n",
    "    df_author_pair = query_polars(conn=conn, query_str=sql_query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d7e0b142-c3a6-44be-973a-e2da10f54013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.37 s, sys: 710 ms, total: 4.08 s\n",
      "Wall time: 9.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "sql_query = f\"\"\"\n",
    "SELECT DISTINCT article_id,\n",
    "                author_id,\n",
    "                article_publication_dt\n",
    "FROM fct_collaboration\n",
    "WHERE author_id IN (SELECT author_id FROM g_included_author)\n",
    "ORDER BY article_publication_dt ASC\n",
    "\"\"\"\n",
    "\n",
    "with pg_engine.connect() as conn:\n",
    "    df_collab = query_polars(conn=conn, query_str=sql_query)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42ef85b5-6063-4346-8bcc-80dc0ae5cf0d",
   "metadata": {},
   "source": [
    "### Prepocessing for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "562aab28-dedb-4dd0-9710-0d1eb50f3b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "354102it [01:09, 5125.25it/s] \n"
     ]
    }
   ],
   "source": [
    "# Build a lookup dictionary for article embeddings\n",
    "article_embeddings = {}\n",
    "for row in tqdm(article_embedding_df.iter_rows(named=True)):\n",
    "    art_id = row[\"article_id\"]\n",
    "    emb = row[\"article_embedding\"]\n",
    "    \n",
    "    if isinstance(emb, list):\n",
    "        emb = np.array(emb, dtype=np.float32)\n",
    "    article_embeddings[art_id] = emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "474c8ecf-f158-4c85-ad6e-654d2cef0b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "973511it [00:07, 137012.12it/s]\n"
     ]
    }
   ],
   "source": [
    "# Build a lookup dictionary for author articles\n",
    "author_articles_map = defaultdict(list)\n",
    "for row in tqdm(df_collab.iter_rows(named=True)):\n",
    "    a_id = row[\"author_id\"]\n",
    "    art_id = row[\"article_id\"]\n",
    "    pub_dt = row[\"article_publication_dt\"]\n",
    "    author_articles_map[a_id].append((art_id, pub_dt))\n",
    "\n",
    "# Sort each author's articles by publication date to handle \"before/after\" queries quickly.\n",
    "for a_id in author_articles_map:\n",
    "    author_articles_map[a_id].sort(key=lambda x: x[1])  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc46d0ec-e06e-4997-a16f-556d5ea5c78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2199026it [00:34, 64080.84it/s] \n"
     ]
    }
   ],
   "source": [
    "# Build a dictionary to check new/existing author pairs\n",
    "is_new_map = {}\n",
    "\n",
    "for row in tqdm(df_author_pair.iter_rows(named=True)):\n",
    "    art_id = row[\"article_id\"]\n",
    "    a1 = row[\"author_id\"]\n",
    "    a2 = row[\"co_author_id\"]\n",
    "    new_flag = row[\"is_new_author_pair\"]\n",
    "    \n",
    "    key = (art_id, frozenset([a1, a2]))\n",
    "    is_new_map[key] = new_flag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ede4630-a453-4bd0-ab2e-b8e8495994be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing top-5 closest articles for an author relative to article p\n",
    "def get_top_k_closest_articles(article_p_id: int, author_id: int, k: int = 5) -> list:\n",
    "    \"\"\"\n",
    "    For a given article p (article_p_id), find the top-k closest articles\n",
    "    from the given author based on cosine distance in embedding space.\n",
    "    Returns a list of (article_id, distance).\n",
    "    \"\"\"\n",
    "    if article_p_id not in article_embeddings:\n",
    "        return []\n",
    "    \n",
    "    emb_p = article_embeddings[article_p_id]\n",
    "    \n",
    "    # Collect all the author's articles\n",
    "    # (In practice, you might exclude article_p_id itself if you don't want self-comparison,\n",
    "    #  or you might only consider articles before p's date, etc. - depends on your logic.)\n",
    "    author_article_list = author_articles_map[author_id]\n",
    "    \n",
    "    # If your logic requires \"articles published before p\", filter accordingly:\n",
    "    # Get publication_dt of p\n",
    "    # (You can fetch it from df_collab or df_author_pair if needed.)\n",
    "    # For demonstration, let's do a naive approach ignoring time:\n",
    "    \n",
    "    distances = []\n",
    "    for (art_id, _) in author_article_list:\n",
    "        if art_id not in article_embeddings:\n",
    "            continue\n",
    "        emb_a = article_embeddings[art_id]\n",
    "        dist = cosine(emb_p, emb_a)  # or 1 - dot(...) / (||p||*||a||) if you want to do it manually\n",
    "        distances.append((art_id, dist))\n",
    "    \n",
    "    # Sort by distance ascending (closest first)\n",
    "    distances.sort(key=lambda x: x[1])\n",
    "    \n",
    "    # Return top k\n",
    "    return distances[:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "54f4d7c5-7ae1-49d6-badd-1cee91ef68ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Computing the distance measure for each pair (a_i, a_j) given article p\n",
    "#    - We retrieve top-5 closest articles from a_i and from a_j\n",
    "#    - We do a cross-comparison for all 5 x 5 pairs in embeddings and measure \n",
    "#      the average distance (or min distance, or however you define it).\n",
    "\n",
    "\n",
    "def compute_pair_distance(article_p_id: int, a_i: int, a_j: int) -> float:\n",
    "    \"\"\"\n",
    "    Compute the \"distance\" for the pair (a_i, a_j) given an article p.\n",
    "\n",
    "    Steps (naive example):\n",
    "      1) Retrieve top 5 articles of a_i that are closest to p\n",
    "      2) Retrieve top 5 articles of a_j that are closest to p\n",
    "      3) For each combination of (article_i, article_j) from these top-5 sets, \n",
    "         compute the cosine distance of their embeddings\n",
    "      4) Return the average of all 25 distances (or any other chosen metric).\n",
    "    \"\"\"\n",
    "    top_5_i = get_top_k_closest_articles(article_p_id, a_i, k=5)  # [(art_id, dist_p_i), ...]\n",
    "    top_5_j = get_top_k_closest_articles(article_p_id, a_j, k=5)\n",
    "    \n",
    "    # If for some reason we can't get any top articles, handle gracefully:\n",
    "    if not top_5_i or not top_5_j:\n",
    "        return math.nan\n",
    "    \n",
    "    # Convert to just article IDs\n",
    "    top_5_i_ids = [x[0] for x in top_5_i]\n",
    "    top_5_j_ids = [x[0] for x in top_5_j]\n",
    "    \n",
    "    distances_ij = []\n",
    "    for art_id_i in top_5_i_ids:\n",
    "        emb_i = article_embeddings.get(art_id_i)\n",
    "        if emb_i is None:\n",
    "            continue\n",
    "        for art_id_j in top_5_j_ids:\n",
    "            emb_j = article_embeddings.get(art_id_j)\n",
    "            if emb_j is None:\n",
    "                continue\n",
    "            d_ij = cosine(emb_i, emb_j)\n",
    "            distances_ij.append(d_ij)\n",
    "    \n",
    "    if len(distances_ij) == 0:\n",
    "        return math.nan\n",
    "    \n",
    "    return float(np.max(distances_ij))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "abb31c70-8bb6-48ac-8454-a21339e6eee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For memory reasons, let's assume we chunk the iteration over df_collab by article_id\n",
    "# or simply group by article_id. We'll do an example with group_by, but watch out for \n",
    "# memory usage if the dataset is huge.\n",
    "grouped = (df_collab\n",
    "           .group_by(\"article_id\", maintain_order=True).agg(\n",
    "               [\n",
    "                   pl.col(\"author_id\").alias(\"authors_of_p\"),\n",
    "                   pl.col(\"article_publication_dt\").first().alias(\"p_pub_dt\"),\n",
    "               ]\n",
    "           )\n",
    "           .filter(pl.col(\"article_id\").is_in(article_embeddings.keys()))\n",
    "          )\n",
    "\n",
    "# Now grouped has shape ~ (#unique articles, 3)\n",
    "#   [article_id, authors_of_p, p_pub_dt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "77e6b476-b156-4296-9830-e7feac6be915",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41616it [10:02, 69.03it/s]  \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 21\u001b[0m\n\u001b[1;32m     18\u001b[0m is_new \u001b[38;5;241m=\u001b[39m is_new_map[key]\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Compute distance for this pair\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m pair_dist \u001b[38;5;241m=\u001b[39m \u001b[43mcompute_pair_distance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mart_p_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_j\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m math\u001b[38;5;241m.\u001b[39misnan(pair_dist):\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;66;03m# skip if we couldn't compute anything\u001b[39;00m\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[60], line 18\u001b[0m, in \u001b[0;36mcompute_pair_distance\u001b[0;34m(article_p_id, a_i, a_j)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_pair_distance\u001b[39m(article_p_id: \u001b[38;5;28mint\u001b[39m, a_i: \u001b[38;5;28mint\u001b[39m, a_j: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mfloat\u001b[39m:\n\u001b[1;32m      8\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;124;03m    Compute the \"distance\" for the pair (a_i, a_j) given an article p.\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;124;03m      4) Return the average of all 25 distances (or any other chosen metric).\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     top_5_i \u001b[38;5;241m=\u001b[39m \u001b[43mget_top_k_closest_articles\u001b[49m\u001b[43m(\u001b[49m\u001b[43marticle_p_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_i\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [(art_id, dist_p_i), ...]\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     top_5_j \u001b[38;5;241m=\u001b[39m get_top_k_closest_articles(article_p_id, a_j, k\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m)\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;66;03m# If for some reason we can't get any top articles, handle gracefully:\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[59], line 28\u001b[0m, in \u001b[0;36mget_top_k_closest_articles\u001b[0;34m(article_p_id, author_id, k)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     emb_a \u001b[38;5;241m=\u001b[39m article_embeddings[art_id]\n\u001b[0;32m---> 28\u001b[0m     dist \u001b[38;5;241m=\u001b[39m \u001b[43mcosine\u001b[49m\u001b[43m(\u001b[49m\u001b[43memb_p\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43memb_a\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# or 1 - dot(...) / (||p||*||a||) if you want to do it manually\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     distances\u001b[38;5;241m.\u001b[39mappend((art_id, dist))\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Sort by distance ascending (closest first)\u001b[39;00m\n",
      "File \u001b[0;32m~/eutopia-colllaboration/ecr-analytics/.venv/lib/python3.12/site-packages/scipy/spatial/distance.py:694\u001b[0m, in \u001b[0;36mcosine\u001b[0;34m(u, v, w)\u001b[0m\n\u001b[1;32m    653\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    654\u001b[0m \u001b[38;5;124;03mCompute the Cosine distance between 1-D arrays.\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    690\u001b[0m \n\u001b[1;32m    691\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    692\u001b[0m \u001b[38;5;66;03m# cosine distance is also referred to as 'uncentered correlation',\u001b[39;00m\n\u001b[1;32m    693\u001b[0m \u001b[38;5;66;03m#   or 'reflective correlation'\u001b[39;00m\n\u001b[0;32m--> 694\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcorrelation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentered\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eutopia-colllaboration/ecr-analytics/.venv/lib/python3.12/site-packages/scipy/spatial/distance.py:649\u001b[0m, in \u001b[0;36mcorrelation\u001b[0;34m(u, v, w, centered)\u001b[0m\n\u001b[1;32m    647\u001b[0m dist \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.0\u001b[39m \u001b[38;5;241m-\u001b[39m uv \u001b[38;5;241m/\u001b[39m math\u001b[38;5;241m.\u001b[39msqrt(uu \u001b[38;5;241m*\u001b[39m vv)\n\u001b[1;32m    648\u001b[0m \u001b[38;5;66;03m# Clip the result to avoid rounding error\u001b[39;00m\n\u001b[0;32m--> 649\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2.0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eutopia-colllaboration/ecr-analytics/.venv/lib/python3.12/site-packages/numpy/core/fromnumeric.py:2169\u001b[0m, in \u001b[0;36mclip\u001b[0;34m(a, a_min, a_max, out, **kwargs)\u001b[0m\n\u001b[1;32m   2100\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_clip_dispatcher)\n\u001b[1;32m   2101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclip\u001b[39m(a, a_min, a_max, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2102\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2103\u001b[0m \u001b[38;5;124;03m    Clip (limit) the values in an array.\u001b[39;00m\n\u001b[1;32m   2104\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2167\u001b[0m \n\u001b[1;32m   2168\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_wrapfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mclip\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_min\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43ma_max\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/eutopia-colllaboration/ecr-analytics/.venv/lib/python3.12/site-packages/numpy/core/fromnumeric.py:59\u001b[0m, in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbound\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;66;03m# A TypeError occurs if the object does have such a method in its\u001b[39;00m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;66;03m# class, but its signature is not identical to that of NumPy's. This\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m# Call _wrapit from within the except clause to ensure a potential\u001b[39;00m\n\u001b[1;32m     67\u001b[0m     \u001b[38;5;66;03m# exception has a traceback chain.\u001b[39;00m\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapit(obj, method, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n",
      "File \u001b[0;32m~/eutopia-colllaboration/ecr-analytics/.venv/lib/python3.12/site-packages/numpy/core/_methods.py:99\u001b[0m, in \u001b[0;36m_clip\u001b[0;34m(a, min, max, out, **kwargs)\u001b[0m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m um\u001b[38;5;241m.\u001b[39mmaximum(a, \u001b[38;5;28mmin\u001b[39m, out\u001b[38;5;241m=\u001b[39mout, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 99\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mum\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmin\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mmax\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "distances_new = []\n",
    "distances_existing = []\n",
    "\n",
    "for row in tqdm(grouped.iter_rows(named=True)):\n",
    "    art_p_id = row[\"article_id\"]\n",
    "    authors_of_p = row[\"authors_of_p\"]\n",
    "    # p_pub_dt = row[\"p_pub_dt\"]  # if you need the date for logic\n",
    "    \n",
    "    # All pair combinations among authors_of_p\n",
    "    # If an article has N authors, that's N*(N-1)/2 pairs\n",
    "    for (a_i, a_j) in combinations(authors_of_p, 2):\n",
    "        # We'll build the lookup key for is_new_map\n",
    "        key = (art_p_id, frozenset([a_i, a_j]))\n",
    "        if key not in is_new_map:\n",
    "            # Possibly you skip or assume \"existing\" if not found\n",
    "            continue\n",
    "        \n",
    "        is_new = is_new_map[key]\n",
    "        \n",
    "        # Compute distance for this pair\n",
    "        pair_dist = compute_pair_distance(art_p_id, a_i, a_j)\n",
    "        if math.isnan(pair_dist):\n",
    "            # skip if we couldn't compute anything\n",
    "            continue\n",
    "        \n",
    "        if is_new:\n",
    "            distances_new.append(pair_dist)\n",
    "        else:\n",
    "            distances_existing.append(pair_dist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7e6e4aff-7d3e-46b2-8202-1b428c27f39a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wasserstein-1 distance (new vs existing): 0.0243\n"
     ]
    }
   ],
   "source": [
    "# Convert to numpy arrays for convenience\n",
    "distances_new = np.array(distances_new, dtype=np.float32)\n",
    "distances_existing = np.array(distances_existing, dtype=np.float32)\n",
    "\n",
    "# You might also want to do some basic cleaning, e.g., remove outliers or check length\n",
    "if len(distances_new) == 0 or len(distances_existing) == 0:\n",
    "    print(\"Not enough data to compute Wasserstein distance.\")\n",
    "else:\n",
    "    w_distance = wasserstein_distance(distances_new, distances_existing)\n",
    "    print(f\"Wasserstein-1 distance (new vs existing): {w_distance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "386d2935-8373-4fa5-9349-88ff00d19c98",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KS test stat: 0.2375562367275667, p-value: 0.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import ks_2samp\n",
    "ks_stat, p_value = ks_2samp(distances_new, distances_existing)\n",
    "print(f\"KS test stat: {ks_stat}, p-value: {p_value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb5b67be-cd75-41bf-8d0c-866a7137b35c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
